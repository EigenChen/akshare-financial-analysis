"""
ä¸‹è½½ä¸Šå¸‚å…¬å¸å¹´åº¦æŠ¥å‘ŠPDF

æ”¯æŒä»ä»¥ä¸‹æ¸ é“ä¸‹è½½ï¼š
1. å·¨æ½®èµ„è®¯ç½‘ï¼ˆcninfo.com.cnï¼‰- æ¨è
2. ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
3. æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€

ä¸‹è½½æ–¹æ³•ï¼š
1. æ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼Œæœ€ç®€å•å¯é ï¼‰
2. ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆSeleniumï¼‰
3. åˆ†æç½‘ç«™APIï¼ˆéœ€è¦æŠ€æœ¯èƒ½åŠ›ï¼‰

æ³¨æ„ï¼šéœ€è¦éµå®ˆç½‘ç«™çš„ä½¿ç”¨æ¡æ¬¾ï¼Œä¸è¦é¢‘ç¹è¯·æ±‚
"""

import os
import re
import time
import requests
from typing import Optional, List, Dict
from pathlib import Path
from urllib.parse import urlparse, parse_qs

# å¦‚æœéœ€è¦ä½¿ç”¨Seleniumï¼Œéœ€è¦å®‰è£…ï¼špip install selenium
# å¹¶ä¸‹è½½å¯¹åº”çš„æµè§ˆå™¨é©±åŠ¨ï¼ˆChromeDriverç­‰ï¼‰
try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("âš  Seleniumæœªå®‰è£…ï¼Œå¦‚éœ€ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–åŠŸèƒ½ï¼Œè¯·è¿è¡Œ: pip install selenium")

def get_stock_market(symbol: str) -> str:
    """
    åˆ¤æ–­è‚¡ç¥¨æ‰€å±äº¤æ˜“æ‰€
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼‰
    
    è¿”å›:
        'SH' æˆ– 'SZ'
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    if symbol_clean.startswith(('600', '601', '603', '605', '688')):
        return 'SH'  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
    elif symbol_clean.startswith(('000', '001', '002', '300')):
        return 'SZ'  # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
    else:
        return 'SZ'  # é»˜è®¤æ·±äº¤æ‰€

def search_announcements_cninfo(symbol: str, year: Optional[int] = None, announcement_type: str = "å¹´åº¦æŠ¥å‘Š") -> List[Dict]:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘æœç´¢å…¬å‘Šï¼ˆä½¿ç”¨å·¨æ½®èµ„è®¯ç½‘çš„å…¬å‘ŠæŸ¥è¯¢APIï¼‰
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸ºNoneåˆ™æœç´¢æ‰€æœ‰å¹´ä»½ï¼‰
        announcement_type: å…¬å‘Šç±»å‹ï¼Œé»˜è®¤ä¸º"å¹´åº¦æŠ¥å‘Š"
    
    è¿”å›:
        å…¬å‘Šåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å…¬å‘Šä¿¡æ¯ï¼ˆåŒ…æ‹¬announcementIdï¼‰
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    # åˆ¤æ–­äº¤æ˜“æ‰€
    if symbol_clean.startswith(('600', '601', '603', '605', '688')):
        plate = 'sh'  # ä¸Šäº¤æ‰€
        column = 'sse'
    else:
        plate = 'sz'  # æ·±äº¤æ‰€
        column = 'szse'
    
    # å·¨æ½®èµ„è®¯ç½‘å…¬å‘Šå†å²æŸ¥è¯¢API
    search_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search',
        'Accept': 'application/json, text/plain, */*',
        'Content-Type': 'application/x-www-form-urlencoded',
        'Origin': 'http://www.cninfo.com.cn',
    }
    
    # æ„å»ºæœç´¢å‚æ•°
    # å¹´æŠ¥é€šå¸¸åœ¨ç¬¬äºŒå¹´3-4æœˆå‘å¸ƒï¼Œæ‰€ä»¥æœç´¢(year+1)å¹´çš„å…¬å‘Š
    # æ‰©å¤§æœç´¢èŒƒå›´åˆ°æ•´å¹´ï¼Œä»¥é˜²æŸäº›å…¬å¸å»¶è¿Ÿå‘å¸ƒ
    if year:
        se_date = f"{year+1}-01-01~{year+1}-12-31"  # æ‰©å¤§åˆ°æ•´å¹´
    else:
        se_date = ""
    
    # å‡†å¤‡å¤šç§æœç´¢ç­–ç•¥
    search_strategies = [
        # ç­–ç•¥1ï¼šä½¿ç”¨è‚¡ç¥¨ä»£ç ä½œä¸ºæœç´¢å…³é”®è¯
        {
            'pageNum': '1',
            'pageSize': '30',
            'column': column,
            'tabName': 'fulltext',
            'plate': '',
            'stock': '',
            'searchkey': symbol_clean,
            'secid': '',
            'category': 'category_ndbg_szsh',
            'trade': '',
            'seDate': se_date,
            'sortName': '',
            'sortType': '',
            'isHLtitle': 'true',
        },
        # ç­–ç•¥2ï¼šä¸é™åˆ¶æ—¥æœŸèŒƒå›´ï¼Œç”¨å¹´ä»½å…³é”®è¯
        {
            'pageNum': '1',
            'pageSize': '50',
            'column': column,
            'tabName': 'fulltext',
            'plate': '',
            'stock': '',
            'searchkey': f"{symbol_clean} {year}å¹´" if year else symbol_clean,
            'secid': '',
            'category': 'category_ndbg_szsh',
            'trade': '',
            'seDate': '',  # ä¸é™åˆ¶æ—¥æœŸ
            'sortName': '',
            'sortType': '',
            'isHLtitle': 'true',
        },
    ]
    
    print(f"  [å·¨æ½®èµ„è®¯ç½‘API] æœç´¢è‚¡ç¥¨: {symbol_clean}, å¹´ä»½: {year if year else 'å…¨éƒ¨'}, æ—¥æœŸèŒƒå›´: {se_date}")
    
    # å°è¯•å¤šç§æœç´¢ç­–ç•¥
    for strategy_idx, data in enumerate(search_strategies, 1):
        try:
            response = requests.post(search_url, headers=headers, data=data, timeout=30)
            
            if response.status_code == 200:
                try:
                    result = response.json()
                except Exception as json_error:
                    print(f"  âš  JSONè§£æå¤±è´¥: {json_error}")
                    continue
                
                announcements = []
                
                # è§£æè¿”å›çš„æ•°æ®
                if isinstance(result, dict):
                    # è·å–å…¬å‘Šåˆ—è¡¨
                    ann_list = result.get('announcements', [])
                    total_count = result.get('totalAnnouncement', 0)
                    
                    print(f"  âœ“ ç­–ç•¥{strategy_idx}æ‰¾åˆ° {total_count} æ¡å…¬å‘Šè®°å½•")
                    
                    if not ann_list:
                        if strategy_idx < len(search_strategies):
                            print(f"  âš  å…¬å‘Šåˆ—è¡¨ä¸ºç©ºï¼Œå°è¯•ä¸‹ä¸€ä¸ªæœç´¢ç­–ç•¥...")
                            continue
                        else:
                            print(f"  âš  å…¬å‘Šåˆ—è¡¨ä¸ºç©º")
                            return []
                    
                    # ç­›é€‰å¹´åº¦æŠ¥å‘Šï¼ˆæ’é™¤æ‘˜è¦ã€è‹±æ–‡ç‰ˆç­‰ï¼‰
                    for ann in ann_list:
                        title = ann.get('announcementTitle', '')
                        ann_id = ann.get('announcementId', '')
                        ann_time = ann.get('announcementTime', '')
                        sec_code = ann.get('secCode', '')  # å…¬å‘Šå¯¹åº”çš„è‚¡ç¥¨ä»£ç 
                        
                        # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ—¥æœŸå­—ç¬¦ä¸²
                        if isinstance(ann_time, (int, float)):
                            from datetime import datetime
                            ann_time = datetime.fromtimestamp(ann_time / 1000).strftime('%Y-%m-%d')
                        
                        # é¦–å…ˆæ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦åŒ¹é…ï¼ˆå› ä¸ºsearchkeyå¯èƒ½è¿”å›å¤šä¸ªè‚¡ç¥¨çš„ç»“æœï¼‰
                        if sec_code and sec_code != symbol_clean:
                            continue  # è·³è¿‡éç›®æ ‡è‚¡ç¥¨çš„å…¬å‘Š
                        
                        # æ‰“å°è°ƒè¯•ä¿¡æ¯
                        print(f"    - [{sec_code}] {title[:55]}... (ID: {ann_id})")
                        
                        # ç­›é€‰ï¼šåªè¦å¹´åº¦æŠ¥å‘Šå…¨æ–‡ï¼Œæ’é™¤æ‘˜è¦ã€è‹±æ–‡ç‰ˆã€æ›´æ­£å…¬å‘Šç­‰
                        is_valid_annual_report = (
                            ('å¹´åº¦æŠ¥å‘Š' in title or 'å¹´æŠ¥' in title) and
                            'æ‘˜è¦' not in title and
                            'è‹±æ–‡' not in title and
                            'æ›´æ­£' not in title and
                            'è¡¥å……' not in title and
                            'ä¿®è®¢' not in title
                        )
                        
                        # å¦‚æœæŒ‡å®šäº†å¹´ä»½ï¼Œæ£€æŸ¥æ ‡é¢˜ä¸­æ˜¯å¦åŒ…å«è¯¥å¹´ä»½
                        if year:
                            year_match = str(year) in title
                        else:
                            year_match = True
                        
                        if is_valid_annual_report and year_match:
                            announcement = {
                                'announcementId': str(ann_id),
                                'id': str(ann_id),
                                'announcementTitle': title,
                                'title': title,
                                'announcementTime': ann_time,
                                'time': ann_time,
                                'secCode': sec_code or symbol_clean,
                                'secName': ann.get('secName', ''),
                                'orgId': ann.get('orgId', ''),  # ä»è¿”å›æ•°æ®è·å–orgId
                                'adjunctUrl': ann.get('adjunctUrl', ''),  # PDFç›¸å¯¹è·¯å¾„
                            }
                            announcements.append(announcement)
                            print(f"  âœ“ åŒ¹é…åˆ°å¹´æŠ¥: {title[:50]}...")
                    
                    # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„å¹´æŠ¥ï¼Œè¿”å›ç»“æœ
                    if announcements:
                        print(f"  [ç»“æœ] æ‰¾åˆ° {len(announcements)} ä¸ªåŒ¹é…çš„å¹´æŠ¥å…¬å‘Š")
                        return announcements
                    else:
                        # æ²¡æ‰¾åˆ°åŒ¹é…çš„å¹´æŠ¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥
                        if strategy_idx < len(search_strategies):
                            print(f"  âš  æœªæ‰¾åˆ°åŒ¹é…çš„å¹´æŠ¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæœç´¢ç­–ç•¥...")
                            continue
                else:
                    print(f"  âš  è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸: {type(result)}")
                    continue
            else:
                print(f"  âš  HTTPçŠ¶æ€ç : {response.status_code}")
                if strategy_idx < len(search_strategies):
                    continue
                    
        except Exception as e:
            print(f"  âœ— ç­–ç•¥{strategy_idx}æœç´¢å¤±è´¥: {str(e)}")
            if strategy_idx < len(search_strategies):
                continue
            import traceback
            traceback.print_exc()
    
    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥
    print(f"  âš  æ‰€æœ‰æœç´¢ç­–ç•¥éƒ½æœªæ‰¾åˆ°åŒ¹é…çš„å¹´æŠ¥")
    return []

def download_pdf_from_cninfo_url(url: str, save_dir: str = "å¹´æŠ¥PDF", filename: Optional[str] = None) -> Optional[str]:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘å…¬å‘Šè¯¦æƒ…é¡µä¸‹è½½PDF
    
    å‚æ•°:
        url: å…¬å‘Šè¯¦æƒ…é¡µURLï¼ˆå¦‚ï¼šhttps://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=...ï¼‰
        save_dir: ä¿å­˜ç›®å½•
        filename: ä¿å­˜çš„æ–‡ä»¶åï¼ˆå¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨ç”Ÿæˆï¼‰
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        
        # ä»URLä¸­æå–å‚æ•°
        parsed = urlparse(url)
        params = parse_qs(parsed.query)
        
        stock_code = params.get('stockCode', [''])[0]
        announcement_id = params.get('announcementId', [''])[0]
        announcement_time = params.get('announcementTime', [''])[0]
        
        if not announcement_id:
            return None
        
        # æ„å»ºPDFä¸‹è½½URLï¼ˆå°è¯•å¤šç§å¯èƒ½çš„æ ¼å¼ï¼‰
        # æ ¼å¼1ï¼šç›´æ¥ä¸‹è½½æ¥å£
        download_urls = [
            f"http://www.cninfo.com.cn/new/disclosure/detail/download?announcementId={announcement_id}",
            f"https://www.cninfo.com.cn/new/disclosure/detail/download?announcementId={announcement_id}",
            f"http://static.cninfo.com.cn/finalpage/{announcement_time.replace('-', '')}/{announcement_id}.PDF",
            f"http://www.cninfo.com.cn/new/disclosure/detail?plate={params.get('plate', [''])[0]}&orgId={params.get('orgId', [''])[0]}&stockCode={stock_code}&announcementId={announcement_id}&announcementTime={announcement_time}&download=true",
        ]
        
        print(f"[PDFä¸‹è½½URLåˆ—è¡¨]")
        for idx, download_url in enumerate(download_urls, 1):
            print(f"  {idx}. {download_url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': url,
            'Accept': 'application/pdf,application/octet-stream,*/*'
        }
        
        # å°è¯•å¤šä¸ªä¸‹è½½URL
        response = None
        success_url = None
        
        for idx, download_url in enumerate(download_urls, 1):
            try:
                print(f"[å°è¯•ä¸‹è½½ {idx}/{len(download_urls)}] {download_url}")
                test_response = requests.get(download_url, headers=headers, timeout=60, stream=True, allow_redirects=True)
                
                print(f"  -> çŠ¶æ€ç : {test_response.status_code}, Content-Type: {test_response.headers.get('Content-Type', 'N/A')}, Content-Length: {test_response.headers.get('Content-Length', 'N/A')}")
                
                # æ£€æŸ¥å“åº”
                if test_response.status_code == 200:
                    content_type = test_response.headers.get('Content-Type', '')
                    content_length = test_response.headers.get('Content-Length', '0')
                    # æ£€æŸ¥æ˜¯å¦æ˜¯PDFï¼ˆé€šè¿‡Content-Typeæˆ–æ–‡ä»¶å¤§å°åˆ¤æ–­ï¼‰
                    if 'pdf' in content_type.lower() or int(content_length) > 10000:  # PDFæ–‡ä»¶é€šå¸¸å¤§äº10KB
                        response = test_response
                        success_url = download_url
                        print(f"  -> âœ“ æ‰¾åˆ°æœ‰æ•ˆPDF")
                        break
                    else:
                        print(f"  -> âœ— ä¸æ˜¯æœ‰æ•ˆPDF")
                elif test_response.status_code in [302, 301]:
                    # é‡å®šå‘ï¼Œå°è¯•è·Ÿéš
                    redirect_url = test_response.headers.get('Location')
                    if redirect_url:
                        print(f"[é‡å®šå‘URL] {redirect_url}")
                        redirect_response = requests.get(redirect_url, headers=headers, timeout=60, stream=True)
                        if redirect_response.status_code == 200:
                            response = redirect_response
                            success_url = redirect_url
                            break
            except Exception as e:
                continue
        
        if response is None or response.status_code != 200:
            print(f"[ä¸‹è½½å¤±è´¥] æ‰€æœ‰URLå°è¯•å¤±è´¥ï¼Œæœ€åçŠ¶æ€ç : {response.status_code if response else 'None'}")
            return None
        
        if success_url:
            print(f"[æˆåŠŸURL] {success_url}")
        
        # ä¸‹è½½æˆåŠŸï¼Œä¿å­˜æ–‡ä»¶
        if response.status_code == 200:
            # ç”Ÿæˆæ–‡ä»¶å
            if not filename:
                year = announcement_time[:4] if announcement_time else "æœªçŸ¥"
                filename = f"{stock_code}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
            
            filepath = os.path.join(save_dir, filename)
            
            # ä¿å­˜æ–‡ä»¶
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            return filepath
        else:
            return None
            
    except Exception as e:
        return None

def download_from_cninfo_with_id(symbol: str, announcement_id: str, announcement_time: str = "", save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä½¿ç”¨å·²çŸ¥çš„announcementIdä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        announcement_id: å…¬å‘ŠID
        announcement_time: å…¬å‘Šæ—¶é—´ï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼š2020-04-10ï¼‰
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    # åˆ¤æ–­äº¤æ˜“æ‰€
    if symbol_clean.startswith(('600', '601', '603', '605', '688')):
        plate = 'sse'
    else:
        plate = 'szse'
    
    # æ„å»ºorgIdï¼ˆå°è¯•å¤šç§æ ¼å¼ï¼‰
    org_id = f"gssh{symbol_clean}"
    
    # æ„å»ºå…¬å‘Šè¯¦æƒ…é¡µURL
    detail_url = f"https://www.cninfo.com.cn/new/disclosure/detail?plate={plate}&orgId={org_id}&stockCode={symbol_clean}&announcementId={announcement_id}"
    if announcement_time:
        detail_url += f"&announcementTime={announcement_time}"
    
    print(f"[å…¬å‘Šè¯¦æƒ…é¡µURL] {detail_url}")
    
    # ç”Ÿæˆæ–‡ä»¶å
    year = announcement_time[:4] if announcement_time else "æœªçŸ¥"
    filename = f"{symbol_clean}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
    
    return download_pdf_from_cninfo_url(detail_url, save_dir, filename)

def download_from_cninfo(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        
        # æœç´¢å¹´æŠ¥å…¬å‘Š
        announcements = search_announcements_cninfo(symbol, year)
        
        if not announcements:
            print(f"  âš  æœªæ‰¾åˆ° {year} å¹´çš„å¹´æŠ¥å…¬å‘Š")
            return None
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„å…¬å‘Š
        announcement = announcements[0]
        announcement_id = announcement.get('announcementId') or announcement.get('id')
        announcement_time = announcement.get('announcementTime') or announcement.get('time', '')
        adjunct_url = announcement.get('adjunctUrl', '')
        title = announcement.get('announcementTitle', '')
        
        print(f"  [é€‰æ‹©å…¬å‘Š] {title[:60]}...")
        print(f"  [å…¬å‘ŠID] {announcement_id}")
        print(f"  [å…¬å‘Šæ—¥æœŸ] {announcement_time}")
        
        if not announcement_id:
            print(f"  âš  æœªè·å–åˆ°å…¬å‘ŠID")
            return None
        
        symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
        
        # æ„å»ºPDFä¸‹è½½URLåˆ—è¡¨ï¼ˆå¤šç§æ ¼å¼ï¼‰
        download_urls = []
        
        # æ–¹å¼1ï¼šä½¿ç”¨adjunctUrlï¼ˆæœ€å¯é ï¼‰
        if adjunct_url:
            pdf_url = f"http://static.cninfo.com.cn/{adjunct_url}"
            download_urls.append(pdf_url)
            print(f"  [PDFè·¯å¾„] {pdf_url}")
        
        # æ–¹å¼2ï¼šä½¿ç”¨å…¬å‘ŠIDç›´æ¥ä¸‹è½½
        download_urls.append(f"http://www.cninfo.com.cn/new/disclosure/detail/download?announcementId={announcement_id}")
        download_urls.append(f"https://www.cninfo.com.cn/new/disclosure/detail/download?announcementId={announcement_id}")
        
        # æ–¹å¼3ï¼šå°è¯•é™æ€é¡µé¢æ ¼å¼
        if announcement_time:
            date_str = announcement_time.replace('-', '')
            download_urls.append(f"http://static.cninfo.com.cn/finalpage/{date_str}/{announcement_id}.PDF")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'http://www.cninfo.com.cn/',
            'Accept': 'application/pdf,application/octet-stream,*/*'
        }
        
        # å°è¯•ä¸‹è½½
        filename = f"{symbol_clean}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
        filepath = os.path.join(save_dir, filename)
        
        for idx, url in enumerate(download_urls, 1):
            try:
                print(f"  [å°è¯•ä¸‹è½½ {idx}/{len(download_urls)}] {url[:80]}...")
                response = requests.get(url, headers=headers, timeout=120, stream=True, allow_redirects=True)
                
                if response.status_code == 200:
                    content_type = response.headers.get('Content-Type', '')
                    content_length = int(response.headers.get('Content-Length', '0'))
                    
                    print(f"    -> çŠ¶æ€ç : 200, Content-Type: {content_type}, å¤§å°: {content_length/1024:.1f}KB")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„PDFï¼ˆé€šè¿‡Content-Typeæˆ–æ–‡ä»¶å¤§å°åˆ¤æ–­ï¼‰
                    if 'pdf' in content_type.lower() or content_length > 50000:  # å¹´æŠ¥PDFé€šå¸¸å¤§äº50KB
                        # ä¿å­˜æ–‡ä»¶
                        with open(filepath, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                        
                        # éªŒè¯æ–‡ä»¶å¤§å°
                        file_size = os.path.getsize(filepath)
                        if file_size > 50000:  # è‡³å°‘50KB
                            print(f"  âœ“ ä¸‹è½½æˆåŠŸ: {filepath} ({file_size/1024:.1f}KB)")
                            return filepath
                        else:
                            print(f"    -> âœ— æ–‡ä»¶å¤ªå° ({file_size}å­—èŠ‚)ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆPDF")
                            os.remove(filepath)
                    else:
                        print(f"    -> âœ— å“åº”ä¸æ˜¯PDFæ ¼å¼")
                else:
                    print(f"    -> âœ— çŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                print(f"    -> âœ— ä¸‹è½½å¤±è´¥: {str(e)}")
                continue
        
        print(f"  âœ— æ‰€æœ‰ä¸‹è½½æ–¹å¼éƒ½å¤±è´¥")
        return None
            
    except Exception as e:
        print(f"  âœ— ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def download_from_sse(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä»ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        return None
        
    except Exception as e:
        return None

def download_from_szse(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä»æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        return None
        
    except Exception as e:
        return None

def download_from_cninfo_url(url: str, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ç›´æ¥ä»å·¨æ½®èµ„è®¯ç½‘å…¬å‘Šè¯¦æƒ…é¡µURLä¸‹è½½PDF
    
    å‚æ•°:
        url: å…¬å‘Šè¯¦æƒ…é¡µURLï¼ˆå®Œæ•´URLï¼Œå¦‚ï¼šhttps://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=...ï¼‰
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    
    ç¤ºä¾‹:
        url = "https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10"
        download_from_cninfo_url(url)
    """
    # ä»URLä¸­æå–ä¿¡æ¯
    parsed = urlparse(url)
    params = parse_qs(parsed.query)
    
    stock_code = params.get('stockCode', [''])[0]
    announcement_time = params.get('announcementTime', [''])[0]
    year = announcement_time[:4] if announcement_time else "æœªçŸ¥"
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"{stock_code}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
    
    return download_pdf_from_cninfo_url(url, save_dir, filename)

def download_annual_report(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF", source: str = "auto") -> Optional[str]:
    """
    ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
        source: æ•°æ®æºï¼Œå¯é€‰ 'cninfo', 'sse', 'szse', 'auto'ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    # è‡ªåŠ¨é€‰æ‹©æ•°æ®æºï¼ˆé»˜è®¤ä½¿ç”¨å·¨æ½®èµ„è®¯ç½‘ï¼Œæ”¯æŒæ‰€æœ‰è‚¡ç¥¨ï¼‰
    if source == "auto":
        source = 'cninfo'
    
    # æ ¹æ®æ•°æ®æºä¸‹è½½
    if source == 'cninfo':
        return download_from_cninfo(symbol_clean, year, save_dir)
    elif source == 'sse':
        return download_from_sse(symbol_clean, year, save_dir)
    elif source == 'szse':
        return download_from_szse(symbol_clean, year, save_dir)
    else:
        print(f"âœ— æœªçŸ¥çš„æ•°æ®æº: {source}")
        return None

def batch_download_annual_reports(symbol: str, years: List[int], save_dir: str = "å¹´æŠ¥PDF") -> Dict[int, str]:
    """
    æ‰¹é‡ä¸‹è½½å¤šå¹´å¹´æŠ¥
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        years: å¹´ä»½åˆ—è¡¨
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        å­—å…¸ï¼Œé”®ä¸ºå¹´ä»½ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„
    """
    results = {}
    
    for year in sorted(years):
        file_path = download_annual_report(symbol, year, save_dir)
        if file_path:
            results[year] = file_path
        else:
            results[year] = None
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)
    
    return results

def download_with_selenium_cninfo(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF", headless: bool = False) -> Optional[str]:
    """
    ä½¿ç”¨Seleniumä»å·¨æ½®èµ„è®¯ç½‘ä¸‹è½½å¹´æŠ¥PDFï¼ˆç¤ºä¾‹ï¼‰
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    
    æ³¨æ„ï¼š
    1. éœ€è¦å®‰è£…Selenium: pip install selenium
    2. éœ€è¦ä¸‹è½½ChromeDriverå¹¶é…ç½®PATH
    3. æ­¤å‡½æ•°ä¸ºç¤ºä¾‹ï¼Œéœ€è¦æ ¹æ®ç½‘ç«™å®é™…ç»“æ„è°ƒæ•´
    """
    if not SELENIUM_AVAILABLE:
        return None
    
    try:
        os.makedirs(save_dir, exist_ok=True)
        
        # é…ç½®Chromeæµè§ˆå™¨
        options = webdriver.ChromeOptions()
        if headless:
            options.add_argument('--headless')
        
        # è®¾ç½®ä¸‹è½½ç›®å½•
        prefs = {
            "download.default_directory": os.path.abspath(save_dir),
            "download.prompt_for_download": False,
        }
        options.add_experimental_option("prefs", prefs)
        
        driver = webdriver.Chrome(options=options)
        
        try:
            # è®¿é—®å·¨æ½®èµ„è®¯ç½‘æœç´¢é¡µé¢
            search_url = f"http://www.cninfo.com.cn/new/information/topSearch/query?keyWord={symbol}"
            driver.get(search_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(2)
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç½‘é¡µç»“æ„æ¥å®šä½å…ƒç´ 
            # ç¤ºä¾‹ï¼šæŸ¥æ‰¾å¹´æŠ¥é“¾æ¥å¹¶ç‚¹å‡»ä¸‹è½½
            # æ³¨æ„ï¼šå®é™…å®ç°éœ€è¦åˆ†æç½‘é¡µHTMLç»“æ„
            
            return None
            
        finally:
            driver.quit()
            
    except Exception as e:
        return None

def main():
    """
    ä¸»å‡½æ•°
    
    ä½¿ç”¨è¯´æ˜ï¼š
    
    æ–¹æ³•1ï¼šæ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼Œæœ€ç®€å•å¯é ï¼‰
    ==========================================
    1. å·¨æ½®èµ„è®¯ç½‘ï¼ˆæ¨èï¼‰ï¼š
       - è®¿é—®ï¼šhttp://www.cninfo.com.cn
       - åœ¨æœç´¢æ¡†è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600728ï¼‰
       - ç‚¹å‡»"å®šæœŸæŠ¥å‘Š"
       - ç­›é€‰"å¹´åº¦æŠ¥å‘Š"
       - é€‰æ‹©å¹´ä»½ï¼Œç‚¹å‡»ä¸‹è½½PDF
    
    2. ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ï¼š
       - è®¿é—®ï¼šhttp://www.sse.com.cn
       - ç‚¹å‡»"æŠ«éœ²" -> "å®šæœŸæŠ¥å‘Š"
       - æœç´¢è‚¡ç¥¨ä»£ç ï¼Œç­›é€‰å¹´æŠ¥
    
    3. æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ï¼š
       - è®¿é—®ï¼šhttp://www.szse.cn
       - ç‚¹å‡»"ä¿¡æ¯æŠ«éœ²" -> "å®šæœŸæŠ¥å‘Š"
       - æœç´¢è‚¡ç¥¨ä»£ç ï¼Œç­›é€‰å¹´æŠ¥
    
    æ–¹æ³•2ï¼šä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆéœ€è¦æŠ€æœ¯èƒ½åŠ›ï¼‰
    ==========================================
    1. å®‰è£…Selenium: pip install selenium
    2. ä¸‹è½½ChromeDriver: https://chromedriver.chromium.org/
    3. åˆ†æç›®æ ‡ç½‘ç«™çš„HTMLç»“æ„
    4. ç¼–å†™è‡ªåŠ¨åŒ–è„šæœ¬
    
    æ–¹æ³•3ï¼šåˆ†æç½‘ç«™APIï¼ˆé«˜çº§ï¼‰
    ==========================================
    1. ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰
    2. åˆ†æç½‘ç»œè¯·æ±‚ï¼Œæ‰¾åˆ°APIæ¥å£
    3. æ¨¡æ‹Ÿè¯·æ±‚ä¸‹è½½PDF
    
    æ¨èå·¥å…·ï¼š
    - æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰
    - Postmanï¼ˆæµ‹è¯•APIï¼‰
    - Seleniumï¼ˆæµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼‰
    """
    print("=" * 80)
    print("ä¸Šå¸‚å…¬å¸å¹´åº¦æŠ¥å‘ŠPDFä¸‹è½½å·¥å…·")
    print("=" * 80)
    print("\nğŸ“‹ ä¸‹è½½æ–¹æ³•è¯´æ˜ï¼š")
    print("\nã€æ–¹æ³•1ã€‘æ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰")
    print("-" * 80)
    print("1. è®¿é—®å·¨æ½®èµ„è®¯ç½‘ï¼šhttp://www.cninfo.com.cn")
    print("2. æœç´¢è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600728ï¼‰")
    print("3. ç‚¹å‡»'å®šæœŸæŠ¥å‘Š' -> ç­›é€‰'å¹´åº¦æŠ¥å‘Š'")
    print("4. é€‰æ‹©å¹´ä»½ï¼Œä¸‹è½½PDF")
    print("\nã€æ–¹æ³•2ã€‘æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆéœ€è¦Seleniumï¼‰")
    print("-" * 80)
    print("1. å®‰è£…: pip install selenium")
    print("2. ä¸‹è½½ChromeDriverå¹¶é…ç½®")
    print("3. ä½¿ç”¨download_with_selenium_cninfo()å‡½æ•°ï¼ˆéœ€è¦æ ¹æ®ç½‘ç«™è°ƒæ•´ï¼‰")
    print("\nã€æ–¹æ³•3ã€‘åˆ†æAPIï¼ˆé«˜çº§ï¼‰")
    print("-" * 80)
    print("1. ä½¿ç”¨æµè§ˆå™¨F12å¼€å‘è€…å·¥å…·")
    print("2. åˆ†æç½‘ç»œè¯·æ±‚ï¼Œæ‰¾åˆ°PDFä¸‹è½½é“¾æ¥")
    print("3. ä½¿ç”¨requestsåº“ç›´æ¥ä¸‹è½½")
    print("\nã€æ–¹æ³•4ã€‘ç›´æ¥ä½¿ç”¨URLä¸‹è½½ï¼ˆæœ€ç®€å•ï¼‰")
    print("-" * 80)
    print("å¦‚æœä½ å·²ç»æœ‰å…¬å‘Šè¯¦æƒ…é¡µçš„URLï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š")
    print("download_from_cninfo_url(url)")
    print("\nURLæ ¼å¼ç¤ºä¾‹ï¼š")
    print("https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10")
    print("\n" + "=" * 80)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("- æ‰‹åŠ¨ä¸‹è½½æœ€å¯é ï¼Œé€‚åˆå°‘é‡æ–‡ä»¶")
    print("- ä½¿ç”¨URLä¸‹è½½ï¼šå¦‚æœä½ æœ‰å…¬å‘ŠURLï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½")
    print("- è‡ªåŠ¨åŒ–ä¸‹è½½é€‚åˆæ‰¹é‡å¤„ç†ï¼Œä½†éœ€è¦æŠ€æœ¯èƒ½åŠ›")
    print("- å»ºè®®å…ˆæ‰‹åŠ¨ä¸‹è½½å‡ ä¸ªæ–‡ä»¶ï¼Œäº†è§£ç½‘ç«™ç»“æ„åå†è€ƒè™‘è‡ªåŠ¨åŒ–")
    print("=" * 80)
    
    # ========== å®é™…æ‰§è¡Œä»£ç  ==========
    # å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥æ‰§è¡Œä¸‹è½½
    
    # ç¤ºä¾‹1ï¼šä½¿ç”¨URLç›´æ¥ä¸‹è½½ï¼ˆå¦‚æœä½ æœ‰å…¬å‘Šè¯¦æƒ…é¡µURLï¼‰
    # url = "https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10"
    # print("\n" + "=" * 80)
    # print("ç¤ºä¾‹1ï¼šä½¿ç”¨URLç›´æ¥ä¸‹è½½")
    # print("=" * 80)
    # download_from_cninfo_url(url, save_dir="å¹´æŠ¥PDF")
    
    # ç¤ºä¾‹2ï¼šä½¿ç”¨è‚¡ç¥¨ä»£ç å’Œå¹´ä»½ä¸‹è½½ï¼ˆè‡ªåŠ¨æœç´¢announcementIdï¼‰
    # symbol = "600728"
    # year = 2020
    # print("\n" + "=" * 80)
    # print(f"ç¤ºä¾‹2ï¼šä¸‹è½½ {symbol} {year} å¹´å¹´æŠ¥")
    # print("=" * 80)
    # download_annual_report(symbol, year, save_dir="å¹´æŠ¥PDF")
    
    # ç¤ºä¾‹3ï¼šæ‰¹é‡ä¸‹è½½å¤šå¹´å¹´æŠ¥
    # symbol = "600728"
    # years = [2020, 2021, 2022, 2023, 2024]
    # print("\n" + "=" * 80)
    # print(f"ç¤ºä¾‹3ï¼šæ‰¹é‡ä¸‹è½½ {symbol} çš„å¹´æŠ¥")
    # print("=" * 80)
    # batch_download_annual_reports(symbol, years, save_dir="å¹´æŠ¥PDF")
    
    # ç¤ºä¾‹4ï¼šå…ˆæœç´¢å…¬å‘Šï¼ŒæŸ¥çœ‹announcementId
    # symbol = "600728"
    # year = 2020
    # print("\n" + "=" * 80)
    # print(f"ç¤ºä¾‹4ï¼šæœç´¢ {symbol} {year} å¹´çš„å¹´æŠ¥å…¬å‘Š")
    # print("=" * 80)
    # announcements = search_announcements_cninfo(symbol, year)
    # if announcements:
    #     print(f"\næ‰¾åˆ° {len(announcements)} ä¸ªå…¬å‘Š")
    #     for ann in announcements:
    #         print(f"  - {ann.get('announcementTitle', 'æœªçŸ¥')}")
    #         print(f"    ID: {ann.get('announcementId', 'æœªçŸ¥')}")
    #         print(f"    æ—¶é—´: {ann.get('announcementTime', 'æœªçŸ¥')}")
    
    # ========== å®é™…æ‰§è¡Œç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šæ¥æ‰§è¡Œï¼‰==========
    
    # æ–¹å¼1ï¼šä½¿ç”¨URLç›´æ¥ä¸‹è½½ï¼ˆæ¨èï¼Œå¦‚æœä½ æœ‰URLï¼‰
    # url = "https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10"
    # download_from_cninfo_url(url, save_dir="å¹´æŠ¥PDF")
    
    # æ–¹å¼2ï¼šä½¿ç”¨è‚¡ç¥¨ä»£ç å’Œå¹´ä»½ï¼ˆè‡ªåŠ¨æœç´¢announcementIdï¼‰
    symbol = "600728"
    year = 2020
    result = download_annual_report(symbol, year, save_dir="å¹´æŠ¥PDF")
    if result:
        print(f"âœ“ ä¸‹è½½æˆåŠŸ: {result}")
    else:
        print(f"âœ— ä¸‹è½½å¤±è´¥")

if __name__ == "__main__":
    main()

