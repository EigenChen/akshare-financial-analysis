"""
ä¸‹è½½ä¸Šå¸‚å…¬å¸å¹´åº¦æŠ¥å‘ŠPDF

æ”¯æŒä»ä»¥ä¸‹æ¸ é“ä¸‹è½½ï¼š
1. å·¨æ½®èµ„è®¯ç½‘ï¼ˆcninfo.com.cnï¼‰- æ¨è
2. ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
3. æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€

ä¸‹è½½æ–¹æ³•ï¼š
1. æ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼Œæœ€ç®€å•å¯é ï¼‰
2. ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆSeleniumï¼‰
3. åˆ†æç½‘ç«™APIï¼ˆéœ€è¦æŠ€æœ¯èƒ½åŠ›ï¼‰

æ³¨æ„ï¼šéœ€è¦éµå®ˆç½‘ç«™çš„ä½¿ç”¨æ¡æ¬¾ï¼Œä¸è¦é¢‘ç¹è¯·æ±‚
"""

import os
import re
import time
import requests
from typing import Optional, List, Dict
from pathlib import Path
from urllib.parse import urlparse, parse_qs

# å¦‚æœéœ€è¦ä½¿ç”¨Seleniumï¼Œéœ€è¦å®‰è£…ï¼špip install selenium
# å¹¶ä¸‹è½½å¯¹åº”çš„æµè§ˆå™¨é©±åŠ¨ï¼ˆChromeDriverç­‰ï¼‰
try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("âš  Seleniumæœªå®‰è£…ï¼Œå¦‚éœ€ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–åŠŸèƒ½ï¼Œè¯·è¿è¡Œ: pip install selenium")

def get_stock_market(symbol: str) -> str:
    """
    åˆ¤æ–­è‚¡ç¥¨æ‰€å±äº¤æ˜“æ‰€
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼‰
    
    è¿”å›:
        'SH' æˆ– 'SZ'
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    if symbol_clean.startswith(('600', '601', '603', '605', '688')):
        return 'SH'  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
    elif symbol_clean.startswith(('000', '001', '002', '300')):
        return 'SZ'  # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
    else:
        return 'SZ'  # é»˜è®¤æ·±äº¤æ‰€

def search_announcements_cninfo(symbol: str, year: Optional[int] = None, announcement_type: str = "å¹´åº¦æŠ¥å‘Š") -> List[Dict]:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘æœç´¢å…¬å‘Š
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸ºNoneåˆ™æœç´¢æ‰€æœ‰å¹´ä»½ï¼‰
        announcement_type: å…¬å‘Šç±»å‹ï¼Œé»˜è®¤ä¸º"å¹´åº¦æŠ¥å‘Š"
    
    è¿”å›:
        å…¬å‘Šåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å…¬å‘Šä¿¡æ¯ï¼ˆåŒ…æ‹¬announcementIdï¼‰
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    # åˆ¤æ–­äº¤æ˜“æ‰€
    if symbol_clean.startswith(('600', '601', '603', '605', '688')):
        plate = 'sse'  # ä¸Šäº¤æ‰€
    else:
        plate = 'szse'  # æ·±äº¤æ‰€
    
    # å·¨æ½®èµ„è®¯ç½‘å…¬å‘ŠæŸ¥è¯¢APIï¼ˆæ ¹æ®å®é™…ç½‘ç«™è°ƒæ•´ï¼‰
    # æ³¨æ„ï¼šè¿™ä¸ªAPIå¯èƒ½éœ€è¦æ ¹æ®ç½‘ç«™å®é™…æƒ…å†µè°ƒæ•´
    search_url = "http://www.cninfo.com.cn/new/information/topSearch/query"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'http://www.cninfo.com.cn/',
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'X-Requested-With': 'XMLHttpRequest'
    }
    
    # æ„å»ºæœç´¢å‚æ•°
    params = {
        'keyWord': symbol_clean,
        'maxSecMarket': plate,
        'minSecMarket': plate,
    }
    
    # æ„å»ºå®Œæ•´æœç´¢URL
    from urllib.parse import urlencode
    full_search_url = f"{search_url}?{urlencode(params)}"
    print(f"[æœç´¢URL] {full_search_url}")
    
    try:
        response = requests.get(search_url, params=params, headers=headers, timeout=30)
        
        if response.status_code == 200:
            try:
                data = response.json()
            except:
                return []
            
            announcements = []
            
            # è§£æè¿”å›çš„æ•°æ®ç»“æ„ï¼ˆéœ€è¦æ ¹æ®å®é™…è¿”å›æ ¼å¼è°ƒæ•´ï¼‰
            # å¯èƒ½çš„æ ¼å¼ï¼š{'records': [...]} æˆ–ç›´æ¥æ˜¯åˆ—è¡¨
            records = []
            if isinstance(data, dict):
                # å°è¯•å¤šç§å¯èƒ½çš„é”®å
                for key in ['records', 'data', 'list', 'announcements']:
                    if key in data:
                        records = data[key]
                        break
            elif isinstance(data, list):
                records = data
            
            # ç­›é€‰å…¬å‘Š
            for record in records:
                if not isinstance(record, dict):
                    continue
                
                title = str(record.get('announcementTitle', record.get('title', '')))
                time_str = str(record.get('announcementTime', record.get('time', record.get('announcementDate', ''))))
                
                # ç­›é€‰å¹´åº¦æŠ¥å‘Š
                if announcement_type in title:
                    # å¦‚æœæŒ‡å®šäº†å¹´ä»½ï¼Œæ£€æŸ¥å¹´ä»½
                    if year is None or str(year) in time_str:
                        announcements.append(record)
            
            return announcements
        else:
            return []
            
    except Exception as e:
        return []

def download_pdf_from_cninfo_url(url: str, save_dir: str = "å¹´æŠ¥PDF", filename: Optional[str] = None) -> Optional[str]:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘å…¬å‘Šè¯¦æƒ…é¡µä¸‹è½½PDF
    
    å‚æ•°:
        url: å…¬å‘Šè¯¦æƒ…é¡µURLï¼ˆå¦‚ï¼šhttps://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=...ï¼‰
        save_dir: ä¿å­˜ç›®å½•
        filename: ä¿å­˜çš„æ–‡ä»¶åï¼ˆå¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨ç”Ÿæˆï¼‰
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        
        # ä»URLä¸­æå–å‚æ•°
        parsed = urlparse(url)
        params = parse_qs(parsed.query)
        
        stock_code = params.get('stockCode', [''])[0]
        announcement_id = params.get('announcementId', [''])[0]
        announcement_time = params.get('announcementTime', [''])[0]
        
        if not announcement_id:
            return None
        
        # æ„å»ºPDFä¸‹è½½URLï¼ˆå°è¯•å¤šç§å¯èƒ½çš„æ ¼å¼ï¼‰
        # æ ¼å¼1ï¼šç›´æ¥ä¸‹è½½æ¥å£
        download_urls = [
            f"http://www.cninfo.com.cn/new/disclosure/detail/download?announcementId={announcement_id}",
            f"https://www.cninfo.com.cn/new/disclosure/detail/download?announcementId={announcement_id}",
            f"http://static.cninfo.com.cn/finalpage/{announcement_time.replace('-', '')}/{announcement_id}.PDF",
            f"http://www.cninfo.com.cn/new/disclosure/detail?plate={params.get('plate', [''])[0]}&orgId={params.get('orgId', [''])[0]}&stockCode={stock_code}&announcementId={announcement_id}&announcementTime={announcement_time}&download=true",
        ]
        
        print(f"[PDFä¸‹è½½URLåˆ—è¡¨]")
        for idx, download_url in enumerate(download_urls, 1):
            print(f"  {idx}. {download_url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': url,
            'Accept': 'application/pdf,application/octet-stream,*/*'
        }
        
        # å°è¯•å¤šä¸ªä¸‹è½½URL
        response = None
        success_url = None
        
        for idx, download_url in enumerate(download_urls, 1):
            try:
                print(f"[å°è¯•ä¸‹è½½ {idx}/{len(download_urls)}] {download_url}")
                test_response = requests.get(download_url, headers=headers, timeout=60, stream=True, allow_redirects=True)
                
                print(f"  -> çŠ¶æ€ç : {test_response.status_code}, Content-Type: {test_response.headers.get('Content-Type', 'N/A')}, Content-Length: {test_response.headers.get('Content-Length', 'N/A')}")
                
                # æ£€æŸ¥å“åº”
                if test_response.status_code == 200:
                    content_type = test_response.headers.get('Content-Type', '')
                    content_length = test_response.headers.get('Content-Length', '0')
                    # æ£€æŸ¥æ˜¯å¦æ˜¯PDFï¼ˆé€šè¿‡Content-Typeæˆ–æ–‡ä»¶å¤§å°åˆ¤æ–­ï¼‰
                    if 'pdf' in content_type.lower() or int(content_length) > 10000:  # PDFæ–‡ä»¶é€šå¸¸å¤§äº10KB
                        response = test_response
                        success_url = download_url
                        print(f"  -> âœ“ æ‰¾åˆ°æœ‰æ•ˆPDF")
                        break
                    else:
                        print(f"  -> âœ— ä¸æ˜¯æœ‰æ•ˆPDF")
                elif test_response.status_code in [302, 301]:
                    # é‡å®šå‘ï¼Œå°è¯•è·Ÿéš
                    redirect_url = test_response.headers.get('Location')
                    if redirect_url:
                        print(f"[é‡å®šå‘URL] {redirect_url}")
                        redirect_response = requests.get(redirect_url, headers=headers, timeout=60, stream=True)
                        if redirect_response.status_code == 200:
                            response = redirect_response
                            success_url = redirect_url
                            break
            except Exception as e:
                continue
        
        if response is None or response.status_code != 200:
            print(f"[ä¸‹è½½å¤±è´¥] æ‰€æœ‰URLå°è¯•å¤±è´¥ï¼Œæœ€åçŠ¶æ€ç : {response.status_code if response else 'None'}")
            return None
        
        if success_url:
            print(f"[æˆåŠŸURL] {success_url}")
        
        # ä¸‹è½½æˆåŠŸï¼Œä¿å­˜æ–‡ä»¶
        if response.status_code == 200:
            # ç”Ÿæˆæ–‡ä»¶å
            if not filename:
                year = announcement_time[:4] if announcement_time else "æœªçŸ¥"
                filename = f"{stock_code}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
            
            filepath = os.path.join(save_dir, filename)
            
            # ä¿å­˜æ–‡ä»¶
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            return filepath
        else:
            return None
            
    except Exception as e:
        return None

def download_from_cninfo_with_id(symbol: str, announcement_id: str, announcement_time: str = "", save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä½¿ç”¨å·²çŸ¥çš„announcementIdä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        announcement_id: å…¬å‘ŠID
        announcement_time: å…¬å‘Šæ—¶é—´ï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼š2020-04-10ï¼‰
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    # åˆ¤æ–­äº¤æ˜“æ‰€
    if symbol_clean.startswith(('600', '601', '603', '605', '688')):
        plate = 'sse'
    else:
        plate = 'szse'
    
    # æ„å»ºorgIdï¼ˆå°è¯•å¤šç§æ ¼å¼ï¼‰
    org_id = f"gssh{symbol_clean}"
    
    # æ„å»ºå…¬å‘Šè¯¦æƒ…é¡µURL
    detail_url = f"https://www.cninfo.com.cn/new/disclosure/detail?plate={plate}&orgId={org_id}&stockCode={symbol_clean}&announcementId={announcement_id}"
    if announcement_time:
        detail_url += f"&announcementTime={announcement_time}"
    
    print(f"[å…¬å‘Šè¯¦æƒ…é¡µURL] {detail_url}")
    
    # ç”Ÿæˆæ–‡ä»¶å
    year = announcement_time[:4] if announcement_time else "æœªçŸ¥"
    filename = f"{symbol_clean}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
    
    return download_pdf_from_cninfo_url(detail_url, save_dir, filename)

def download_from_cninfo(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        # æœç´¢å¹´æŠ¥å…¬å‘Š
        announcements = search_announcements_cninfo(symbol, year)
        
        if not announcements:
            return None
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„å…¬å‘Š
        announcement = announcements[0]
        announcement_id = announcement.get('announcementId') or announcement.get('id')
        announcement_time = announcement.get('announcementTime') or announcement.get('time') or announcement.get('announcementDate', '')
        
        if not announcement_id:
            return None
        
        # æ„å»ºå…¬å‘Šè¯¦æƒ…é¡µURL
        symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
        if symbol_clean.startswith(('600', '601', '603', '605', '688')):
            plate = 'sse'
        else:
            plate = 'szse'
        
        # å°è¯•ä»å…¬å‘Šæ•°æ®ä¸­è·å–orgIdï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ ¼å¼
        org_id = announcement.get('orgId') or announcement.get('orgCode') or f"gssh{symbol_clean}"
        
        detail_url = f"https://www.cninfo.com.cn/new/disclosure/detail?plate={plate}&orgId={org_id}&stockCode={symbol_clean}&announcementId={announcement_id}"
        if announcement_time:
            detail_url += f"&announcementTime={announcement_time}"
        
        print(f"[å…¬å‘Šè¯¦æƒ…é¡µURL] {detail_url}")
        
        # ä¸‹è½½PDF
        filename = f"{symbol_clean}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
        return download_pdf_from_cninfo_url(detail_url, save_dir, filename)
            
    except Exception as e:
        return None

def download_from_sse(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä»ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        return None
        
    except Exception as e:
        return None

def download_from_szse(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ä»æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        os.makedirs(save_dir, exist_ok=True)
        return None
        
    except Exception as e:
        return None

def download_from_cninfo_url(url: str, save_dir: str = "å¹´æŠ¥PDF") -> Optional[str]:
    """
    ç›´æ¥ä»å·¨æ½®èµ„è®¯ç½‘å…¬å‘Šè¯¦æƒ…é¡µURLä¸‹è½½PDF
    
    å‚æ•°:
        url: å…¬å‘Šè¯¦æƒ…é¡µURLï¼ˆå®Œæ•´URLï¼Œå¦‚ï¼šhttps://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=...ï¼‰
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    
    ç¤ºä¾‹:
        url = "https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10"
        download_from_cninfo_url(url)
    """
    # ä»URLä¸­æå–ä¿¡æ¯
    parsed = urlparse(url)
    params = parse_qs(parsed.query)
    
    stock_code = params.get('stockCode', [''])[0]
    announcement_time = params.get('announcementTime', [''])[0]
    year = announcement_time[:4] if announcement_time else "æœªçŸ¥"
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"{stock_code}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
    
    return download_pdf_from_cninfo_url(url, save_dir, filename)

def download_annual_report(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF", source: str = "auto") -> Optional[str]:
    """
    ä¸‹è½½å¹´æŠ¥PDF
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
        source: æ•°æ®æºï¼Œå¯é€‰ 'cninfo', 'sse', 'szse', 'auto'ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    symbol_clean = symbol.replace('.SZ', '').replace('.SH', '')
    
    # è‡ªåŠ¨é€‰æ‹©æ•°æ®æºï¼ˆé»˜è®¤ä½¿ç”¨å·¨æ½®èµ„è®¯ç½‘ï¼Œæ”¯æŒæ‰€æœ‰è‚¡ç¥¨ï¼‰
    if source == "auto":
        source = 'cninfo'
    
    # æ ¹æ®æ•°æ®æºä¸‹è½½
    if source == 'cninfo':
        return download_from_cninfo(symbol_clean, year, save_dir)
    elif source == 'sse':
        return download_from_sse(symbol_clean, year, save_dir)
    elif source == 'szse':
        return download_from_szse(symbol_clean, year, save_dir)
    else:
        print(f"âœ— æœªçŸ¥çš„æ•°æ®æº: {source}")
        return None

def batch_download_annual_reports(symbol: str, years: List[int], save_dir: str = "å¹´æŠ¥PDF") -> Dict[int, str]:
    """
    æ‰¹é‡ä¸‹è½½å¤šå¹´å¹´æŠ¥
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        years: å¹´ä»½åˆ—è¡¨
        save_dir: ä¿å­˜ç›®å½•
    
    è¿”å›:
        å­—å…¸ï¼Œé”®ä¸ºå¹´ä»½ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„
    """
    results = {}
    
    for year in sorted(years):
        file_path = download_annual_report(symbol, year, save_dir)
        if file_path:
            results[year] = file_path
        else:
            results[year] = None
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)
    
    return results

def download_with_selenium_cninfo(symbol: str, year: int, save_dir: str = "å¹´æŠ¥PDF", headless: bool = False) -> Optional[str]:
    """
    ä½¿ç”¨Seleniumä»å·¨æ½®èµ„è®¯ç½‘ä¸‹è½½å¹´æŠ¥PDFï¼ˆç¤ºä¾‹ï¼‰
    
    å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç 
        year: å¹´ä»½
        save_dir: ä¿å­˜ç›®å½•
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
    
    è¿”å›:
        ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    
    æ³¨æ„ï¼š
    1. éœ€è¦å®‰è£…Selenium: pip install selenium
    2. éœ€è¦ä¸‹è½½ChromeDriverå¹¶é…ç½®PATH
    3. æ­¤å‡½æ•°ä¸ºç¤ºä¾‹ï¼Œéœ€è¦æ ¹æ®ç½‘ç«™å®é™…ç»“æ„è°ƒæ•´
    """
    if not SELENIUM_AVAILABLE:
        return None
    
    try:
        os.makedirs(save_dir, exist_ok=True)
        
        # é…ç½®Chromeæµè§ˆå™¨
        options = webdriver.ChromeOptions()
        if headless:
            options.add_argument('--headless')
        
        # è®¾ç½®ä¸‹è½½ç›®å½•
        prefs = {
            "download.default_directory": os.path.abspath(save_dir),
            "download.prompt_for_download": False,
        }
        options.add_experimental_option("prefs", prefs)
        
        driver = webdriver.Chrome(options=options)
        
        try:
            # è®¿é—®å·¨æ½®èµ„è®¯ç½‘æœç´¢é¡µé¢
            search_url = f"http://www.cninfo.com.cn/new/information/topSearch/query?keyWord={symbol}"
            driver.get(search_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(2)
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç½‘é¡µç»“æ„æ¥å®šä½å…ƒç´ 
            # ç¤ºä¾‹ï¼šæŸ¥æ‰¾å¹´æŠ¥é“¾æ¥å¹¶ç‚¹å‡»ä¸‹è½½
            # æ³¨æ„ï¼šå®é™…å®ç°éœ€è¦åˆ†æç½‘é¡µHTMLç»“æ„
            
            return None
            
        finally:
            driver.quit()
            
    except Exception as e:
        return None

def main():
    """
    ä¸»å‡½æ•°
    
    ä½¿ç”¨è¯´æ˜ï¼š
    
    æ–¹æ³•1ï¼šæ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼Œæœ€ç®€å•å¯é ï¼‰
    ==========================================
    1. å·¨æ½®èµ„è®¯ç½‘ï¼ˆæ¨èï¼‰ï¼š
       - è®¿é—®ï¼šhttp://www.cninfo.com.cn
       - åœ¨æœç´¢æ¡†è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600728ï¼‰
       - ç‚¹å‡»"å®šæœŸæŠ¥å‘Š"
       - ç­›é€‰"å¹´åº¦æŠ¥å‘Š"
       - é€‰æ‹©å¹´ä»½ï¼Œç‚¹å‡»ä¸‹è½½PDF
    
    2. ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ï¼š
       - è®¿é—®ï¼šhttp://www.sse.com.cn
       - ç‚¹å‡»"æŠ«éœ²" -> "å®šæœŸæŠ¥å‘Š"
       - æœç´¢è‚¡ç¥¨ä»£ç ï¼Œç­›é€‰å¹´æŠ¥
    
    3. æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ï¼š
       - è®¿é—®ï¼šhttp://www.szse.cn
       - ç‚¹å‡»"ä¿¡æ¯æŠ«éœ²" -> "å®šæœŸæŠ¥å‘Š"
       - æœç´¢è‚¡ç¥¨ä»£ç ï¼Œç­›é€‰å¹´æŠ¥
    
    æ–¹æ³•2ï¼šä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆéœ€è¦æŠ€æœ¯èƒ½åŠ›ï¼‰
    ==========================================
    1. å®‰è£…Selenium: pip install selenium
    2. ä¸‹è½½ChromeDriver: https://chromedriver.chromium.org/
    3. åˆ†æç›®æ ‡ç½‘ç«™çš„HTMLç»“æ„
    4. ç¼–å†™è‡ªåŠ¨åŒ–è„šæœ¬
    
    æ–¹æ³•3ï¼šåˆ†æç½‘ç«™APIï¼ˆé«˜çº§ï¼‰
    ==========================================
    1. ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰
    2. åˆ†æç½‘ç»œè¯·æ±‚ï¼Œæ‰¾åˆ°APIæ¥å£
    3. æ¨¡æ‹Ÿè¯·æ±‚ä¸‹è½½PDF
    
    æ¨èå·¥å…·ï¼š
    - æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰
    - Postmanï¼ˆæµ‹è¯•APIï¼‰
    - Seleniumï¼ˆæµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼‰
    """
    print("=" * 80)
    print("ä¸Šå¸‚å…¬å¸å¹´åº¦æŠ¥å‘ŠPDFä¸‹è½½å·¥å…·")
    print("=" * 80)
    print("\nğŸ“‹ ä¸‹è½½æ–¹æ³•è¯´æ˜ï¼š")
    print("\nã€æ–¹æ³•1ã€‘æ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰")
    print("-" * 80)
    print("1. è®¿é—®å·¨æ½®èµ„è®¯ç½‘ï¼šhttp://www.cninfo.com.cn")
    print("2. æœç´¢è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600728ï¼‰")
    print("3. ç‚¹å‡»'å®šæœŸæŠ¥å‘Š' -> ç­›é€‰'å¹´åº¦æŠ¥å‘Š'")
    print("4. é€‰æ‹©å¹´ä»½ï¼Œä¸‹è½½PDF")
    print("\nã€æ–¹æ³•2ã€‘æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆéœ€è¦Seleniumï¼‰")
    print("-" * 80)
    print("1. å®‰è£…: pip install selenium")
    print("2. ä¸‹è½½ChromeDriverå¹¶é…ç½®")
    print("3. ä½¿ç”¨download_with_selenium_cninfo()å‡½æ•°ï¼ˆéœ€è¦æ ¹æ®ç½‘ç«™è°ƒæ•´ï¼‰")
    print("\nã€æ–¹æ³•3ã€‘åˆ†æAPIï¼ˆé«˜çº§ï¼‰")
    print("-" * 80)
    print("1. ä½¿ç”¨æµè§ˆå™¨F12å¼€å‘è€…å·¥å…·")
    print("2. åˆ†æç½‘ç»œè¯·æ±‚ï¼Œæ‰¾åˆ°PDFä¸‹è½½é“¾æ¥")
    print("3. ä½¿ç”¨requestsåº“ç›´æ¥ä¸‹è½½")
    print("\nã€æ–¹æ³•4ã€‘ç›´æ¥ä½¿ç”¨URLä¸‹è½½ï¼ˆæœ€ç®€å•ï¼‰")
    print("-" * 80)
    print("å¦‚æœä½ å·²ç»æœ‰å…¬å‘Šè¯¦æƒ…é¡µçš„URLï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š")
    print("download_from_cninfo_url(url)")
    print("\nURLæ ¼å¼ç¤ºä¾‹ï¼š")
    print("https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10")
    print("\n" + "=" * 80)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("- æ‰‹åŠ¨ä¸‹è½½æœ€å¯é ï¼Œé€‚åˆå°‘é‡æ–‡ä»¶")
    print("- ä½¿ç”¨URLä¸‹è½½ï¼šå¦‚æœä½ æœ‰å…¬å‘ŠURLï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½")
    print("- è‡ªåŠ¨åŒ–ä¸‹è½½é€‚åˆæ‰¹é‡å¤„ç†ï¼Œä½†éœ€è¦æŠ€æœ¯èƒ½åŠ›")
    print("- å»ºè®®å…ˆæ‰‹åŠ¨ä¸‹è½½å‡ ä¸ªæ–‡ä»¶ï¼Œäº†è§£ç½‘ç«™ç»“æ„åå†è€ƒè™‘è‡ªåŠ¨åŒ–")
    print("=" * 80)
    
    # ========== å®é™…æ‰§è¡Œä»£ç  ==========
    # å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥æ‰§è¡Œä¸‹è½½
    
    # ç¤ºä¾‹1ï¼šä½¿ç”¨URLç›´æ¥ä¸‹è½½ï¼ˆå¦‚æœä½ æœ‰å…¬å‘Šè¯¦æƒ…é¡µURLï¼‰
    # url = "https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10"
    # print("\n" + "=" * 80)
    # print("ç¤ºä¾‹1ï¼šä½¿ç”¨URLç›´æ¥ä¸‹è½½")
    # print("=" * 80)
    # download_from_cninfo_url(url, save_dir="å¹´æŠ¥PDF")
    
    # ç¤ºä¾‹2ï¼šä½¿ç”¨è‚¡ç¥¨ä»£ç å’Œå¹´ä»½ä¸‹è½½ï¼ˆè‡ªåŠ¨æœç´¢announcementIdï¼‰
    # symbol = "600728"
    # year = 2020
    # print("\n" + "=" * 80)
    # print(f"ç¤ºä¾‹2ï¼šä¸‹è½½ {symbol} {year} å¹´å¹´æŠ¥")
    # print("=" * 80)
    # download_annual_report(symbol, year, save_dir="å¹´æŠ¥PDF")
    
    # ç¤ºä¾‹3ï¼šæ‰¹é‡ä¸‹è½½å¤šå¹´å¹´æŠ¥
    # symbol = "600728"
    # years = [2020, 2021, 2022, 2023, 2024]
    # print("\n" + "=" * 80)
    # print(f"ç¤ºä¾‹3ï¼šæ‰¹é‡ä¸‹è½½ {symbol} çš„å¹´æŠ¥")
    # print("=" * 80)
    # batch_download_annual_reports(symbol, years, save_dir="å¹´æŠ¥PDF")
    
    # ç¤ºä¾‹4ï¼šå…ˆæœç´¢å…¬å‘Šï¼ŒæŸ¥çœ‹announcementId
    # symbol = "600728"
    # year = 2020
    # print("\n" + "=" * 80)
    # print(f"ç¤ºä¾‹4ï¼šæœç´¢ {symbol} {year} å¹´çš„å¹´æŠ¥å…¬å‘Š")
    # print("=" * 80)
    # announcements = search_announcements_cninfo(symbol, year)
    # if announcements:
    #     print(f"\næ‰¾åˆ° {len(announcements)} ä¸ªå…¬å‘Š")
    #     for ann in announcements:
    #         print(f"  - {ann.get('announcementTitle', 'æœªçŸ¥')}")
    #         print(f"    ID: {ann.get('announcementId', 'æœªçŸ¥')}")
    #         print(f"    æ—¶é—´: {ann.get('announcementTime', 'æœªçŸ¥')}")
    
    # ========== å®é™…æ‰§è¡Œç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šæ¥æ‰§è¡Œï¼‰==========
    
    # æ–¹å¼1ï¼šä½¿ç”¨URLç›´æ¥ä¸‹è½½ï¼ˆæ¨èï¼Œå¦‚æœä½ æœ‰URLï¼‰
    # url = "https://www.cninfo.com.cn/new/disclosure/detail?plate=sse&orgId=gssh0600728&stockCode=600728&announcementId=1207475136&announcementTime=2020-04-10"
    # download_from_cninfo_url(url, save_dir="å¹´æŠ¥PDF")
    
    # æ–¹å¼2ï¼šä½¿ç”¨è‚¡ç¥¨ä»£ç å’Œå¹´ä»½ï¼ˆè‡ªåŠ¨æœç´¢announcementIdï¼‰
    symbol = "600728"
    year = 2020
    result = download_annual_report(symbol, year, save_dir="å¹´æŠ¥PDF")
    if result:
        print(f"âœ“ ä¸‹è½½æˆåŠŸ: {result}")
    else:
        print(f"âœ— ä¸‹è½½å¤±è´¥")

if __name__ == "__main__":
    main()

